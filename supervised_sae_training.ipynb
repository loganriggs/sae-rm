{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/dictionary_learning/circ/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/root/dictionary_learning/circ/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"reciprocate/dahoas-gptj-rm-static\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "We want the dataset to be sorted (not chunked and tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "hh = load_dataset(\"Anthropic/hh-rlhf\", split=\"train\")\n",
    "token_length_cutoff = 870 # 99% of chosen data\n",
    "\n",
    "# Remove datapoints longer than a specific token_length\n",
    "# Check if file exists\n",
    "index_file_name = \"rm_save_files/index_small_enough.pt\"\n",
    "dataset_size = hh.num_rows\n",
    "if os.path.exists(index_file_name):\n",
    "    index_small_enough = torch.load(index_file_name)\n",
    "else:\n",
    "    index_small_enough = torch.ones(dataset_size, dtype=torch.bool)\n",
    "\n",
    "    for ind, text in enumerate(tqdm(hh)):\n",
    "        chosen_text = text[\"chosen\"]\n",
    "        rejected_text = text[\"rejected\"]\n",
    "        #convert to tokens\n",
    "        length_chosen = len(tokenizer(chosen_text)[\"input_ids\"])\n",
    "        length_rejected = len(tokenizer(rejected_text)[\"input_ids\"])\n",
    "        if length_chosen > token_length_cutoff or length_rejected > token_length_cutoff:\n",
    "            index_small_enough[ind] = False\n",
    "    # Save the indices\n",
    "    torch.save(index_small_enough, \"rm_save_files/index_small_enough.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh.select(index_small_enough.nonzero()[:, 0])\n",
    "batch_size = 16\n",
    "hh_dl = DataLoader(hh, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Supervised-SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an SAE for ablation\n",
    "\"\"\"\n",
    "Defines the dictionary classes\n",
    "\"\"\"\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A one-layer autoencoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, activation_dim, dict_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_dim = activation_dim\n",
    "        self.dict_size = dict_size\n",
    "        self.bias = nn.Parameter(t.zeros(activation_dim))\n",
    "        self.encoder = nn.Linear(activation_dim, dict_size, bias=True)\n",
    "\n",
    "        # rows of decoder weight matrix are unit vectors\n",
    "        self.decoder = nn.Linear(dict_size, activation_dim, bias=False)\n",
    "        dec_weight = t.randn_like(self.decoder.weight)\n",
    "        dec_weight = dec_weight / dec_weight.norm(dim=0, keepdim=True)\n",
    "        self.decoder.weight = nn.Parameter(dec_weight)\n",
    "\n",
    "    def encode(self, x):\n",
    "        return nn.ReLU()(self.encoder(x))\n",
    "    \n",
    "    def decode(self, f):\n",
    "        return self.decoder(f) + self.bias\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of an autoencoder.\n",
    "        x : activations to be autoencoded\n",
    "        \"\"\"\n",
    "        f = self.encode(x)\n",
    "        x_hat = self.decode(f)\n",
    "        return x_hat\n",
    "        \n",
    "    def from_pretrained(path, device=None):\n",
    "        \"\"\"\n",
    "        Load a pretrained autoencoder from a file.\n",
    "        \"\"\"\n",
    "        state_dict = t.load(path)\n",
    "        dict_size, activation_dim = state_dict['encoder.weight'].shape\n",
    "        autoencoder = AutoEncoder(activation_dim, dict_size)\n",
    "        autoencoder.load_state_dict(state_dict)\n",
    "        if device is not None:\n",
    "            autoencoder.to(device)\n",
    "        return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_ind, batch in enumerate(tqdm(hh_dl)):\n",
    "    batch = tokenizer(batch['chosen'], padding=\"longest\", truncation=True, return_attention_mask=False, return_tensors=\"pt\")\n",
    "    batch = batch[\"input_ids\"].to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Search: Attribution Patching (AP) w/ Zero-Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
